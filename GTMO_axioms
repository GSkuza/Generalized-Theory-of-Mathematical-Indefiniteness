# GTMØ – Generalized Theory of Mathematical Indefiniteness (Ø)
# Kompletny system: Aksjomaty, definicje, twierdzenia, równania, dedukcje, operatory, sprzężenie zwrotne, dynamiczne progi

# --- FORMAL DEFINITIONS ---    # EN: FORMAL DEFINITIONS
# --- DEFINICJE FORMALNE ---    # PL: DEFINICJE FORMALNE
DEF1 = "Definition: Knowledge particle Ψᴷ – a fragment such that Ψ_GTMØ(x) ≥ dynamic particle threshold."
DEF2 = "Definition: Knowledge shadow Ψʰ – a fragment such that Ψ_GTMØ(x) ≤ dynamic shadow threshold."
DEF3 = "Definition: Cognitive entropy E_GTMØ(x) = -Σ pᵢ log₂ pᵢ, where pᵢ are semantic partitions of x."
DEF1_dyn = "(Dynamic) Definition: Knowledge particle Ψᴷ – fragment with Ψ_GTMØ(x) ≥ particle threshold (dynamic percentile)."
DEF2_dyn = "(Dynamic) Definition: Knowledge shadow Ψʰ – fragment with Ψ_GTMØ(x) ≤ shadow threshold (dynamic percentile)."
DEF1_pl = "Definicja: Cząstka wiedzy Ψᴷ – fragment poznania, dla którego Ψ_GTMØ(x) ≥ dynamiczny próg cząstek."
DEF2_pl = "Definicja: Cień wiedzy Ψʰ – fragment o Ψ_GTMØ(x) ≤ dynamiczny próg cieni."
DEF3_pl = "Definicja: Entropia poznawcza E_GTMØ(x) = -Σ pᵢ log₂ pᵢ, pᵢ – podziały semantyczne x."
DEF1_dyn_pl = "Definicja (dynamiczna): Cząstka wiedzy Ψᴷ – fragment, dla którego Ψ_GTMØ(x) ≥ próg_cząstek (dynamiczny percentyl)."
DEF2_dyn_pl = "Definicja (dynamiczna): Cień wiedzy Ψʰ – fragment, dla którego Ψ_GTMØ(x) ≤ próg_cieni (dynamiczny percentyl)."
GTMØ_definitions = [DEF1, DEF2, DEF3, DEF1_dyn, DEF2_dyn, DEF1_pl, DEF2_pl, DEF3_pl, DEF1_dyn_pl, DEF2_dyn_pl]

# --- AXIOMS GTMØ ---            # EN: AXIOMS GTMØ
# --- AKSJOMATY GTMØ ---         # PL: AKSJOMATY GTMØ
AX1 = "Ø is a fundamentally different mathematical category: Ø ∉ {0, 1, ∞} ∧ ¬∃f, D: f(D) = Ø, D ⊆ {0,1,∞}"
AX2 = "Translogical isolation: ¬∃f: D → Ø, D ⊆ DefinableSystems"
AX3 = "Epistemic singularity: ¬∃S: Know(Ø) ∈ S, S ∈ CognitiveSystems"
AX4 = "Non-representability: Ø ∉ Repr(S), ∀S ⊇ {0,1,∞}"
AX5 = "Topological boundary: Ø ∈ ∂(CognitiveSpace)"
AX6 = "Heuristic extremum: E_GTMØ(Ø) = min E_GTMØ(x), x ∈ KnowledgeDomain"
AX7 = "Meta-closure: Ø ∈ MetaClosure(GTMØ) ∧ Ø triggers system self-evaluation"
# --- MODYFIKOWANE AKSJOMATY ---
AX8_v2 = "Ø is not a topological limit point: ¬∃Seq(xₙ) ⊆ Domain(GTMØ): lim(xₙ) = Ø"
AX9_v2 = "Operator irreducibility (strict): ¬∃Op ∈ StandardOperators: Op(Ø) = x, x ∈ Domain(GTMØ)"
AX10 = "Meta-operator definition: Ψ_GTMØ, E_GTMØ are meta-operators acting on Ø"
GTMØ_axioms = [AX1, AX2, AX3, AX4, AX5, AX6, AX7, AX8_v2, AX9_v2, AX10]

# --- THEOREMS, EQUATIONS, DEDUCTIONS --- # EN: THEOREMS, ...  # PL: TWIERDZENIA, ...
TH1 = "Ø is not the limit of any defined process: ¬lim(x→∞) f(x) = Ø"
TH2 = "Ø is not part of any semantic category: ∀S ∈ SemanticSystems, Ø ∉ Categories(S)"
TH3 = "Ø determines the minimum of cognitive entropy: ∀x, E_GTMØ(Ø) ≤ E_GTMØ(x)"
TH4 = "Ø is a boundary of any knowledge domain: ∀S, Ø ∈ ∂S"
TH5 = "Ø is irreducible to any system transformation: ¬∃Φ: Φ(Ø) = P, P ∈ Domain(GTMØ)"
TH6 = "For any knowledge particle Ψᴷ, Ψ_GTMØ(Ψᴷ) ≥ dynamic particle threshold ∧ E_GTMØ(Ψᴷ) ≪ E_GTMØ(Ψʰ)"
TH7 = "For any knowledge shadow Ψʰ, Ψ_GTMØ(Ψʰ) ≤ dynamic shadow threshold ∧ E_GTMØ(Ψʰ) ≫ E_GTMØ(Ψᴷ)"
TH8 = "Classification thresholds Ψᴷ and Ψʰ are a function of the global knowledge quality distribution: ∃f: threshold_Ψᴷ, threshold_Ψʰ = f(scores, t)"
TH9 = "GTMØ minimizes cognitive noise and adapts the boundary of sense through iterative self-evaluation of thresholds."
GTMØ_theorems = [TH1, TH2, TH3, TH4, TH5, TH6, TH7, TH8, TH9]

# --- OPERATIONAL THEOREMS GTMØ --- # EN: OPERATIONAL THEOREMS ... # PL: TWIERDZENIA OPERACYJNE ...
# Placeholder for operational theorems - define them here if available
# Poniżej miejsce na zdefiniowanie twierdzeń operacyjnych - dodaj je, jeśli są dostępne
GTMØ_operational_theorems = []
# Przykład, gdyby istniały:
# OTH1 = "Operational Theorem 1: Description of the theorem."
# GTMØ_operational_theorems = [OTH1]


# --- OPERATORS GTMØ ---        # EN: OPERATORS GTMØ
# --- OPERATORY GTMØ ---        # PL: OPERATORY GTMØ

def dynamic_thresholds(all_scores, K_percentile=85, H_percentile=15):
    """
    EN: Computes dynamic thresholds Ψᴷ/Ψʰ for classification based on the percentile of global score distribution.
    PL: Oblicza dynamiczne progi Ψᴷ/Ψʰ do klasyfikacji na podstawie percentyli globalnego rozkładu score.
    """
    import numpy as np
    if not all_scores: # Handle empty list to avoid numpy error
        return 0.0, 0.0
    K_thr = np.percentile(all_scores, K_percentile)
    H_thr = np.percentile(all_scores, H_percentile)
    return K_thr, H_thr

def φ_GTMØ(t):
    """
    EN: Returns cognitive trajectory at time t with a singularity at Ø.
    PL: Zwraca trajektorię poznawczą w czasie t z osobliwością przy Ø.
    """
    return f"φ_GTMØ({t}) = Trajectory(t) with singularity at Ø"

class Operator:
    STANDARD = 1
    META = 2

def Ψ_GTMØ(x, all_scores, operator_type=Operator.META):
    """
    EN: Returns score and type, supporting meta-operator logic for Ø.
    PL: Zwraca score i typ, wspierając logikę meta-operatora dla Ø.
    """
    if x == "Ø":
        if operator_type != Operator.META:
            raise ValueError("Standard operators cannot process Ø")
        return {'score': 1.0, 'type': "Ø (singularity)"}
    
    import random
    score = random.uniform(0, 1)
    K_thr, H_thr = dynamic_thresholds(all_scores if all_scores else [score]) # ensure all_scores is not empty for dynamic_thresholds
    
    if score >= K_thr:
        label = "Ψᴷ (particle)"
    elif score <= H_thr:
        label = "Ψʰ (shadow)"
    else:
        label = "Ψᴧ (other fragment)"
    return {
        'score': score,
        'type': label,
        'thresholds': {'K_thr': K_thr, 'H_thr': H_thr},
        'explanation': f"Dynamic thresholds: Ψᴷ ≥ {K_thr:.2f}, Ψʰ ≤ {H_thr:.2f}; score={score:.2f}"
    }

def E_GTMØ(x):
    """
    EN: Returns total entropy and partitioned entropy (Ψᴷ, Ψʰ) for a knowledge fragment.
    PL: Zwraca całkowitą entropię i entropię podzieloną (Ψᴷ, Ψʰ) dla fragmentu wiedzy.
    """
    import math
    # EN/PL: Dummy partition – replace with real semantic split if x is analyzed.
    # For Ø, entropy is minimal (as per AX6), but this function isn't specific to Ø.
    # This could be extended: if x == "Ø": return {'total_entropy': 0, ...} (or a very small value)
    parts = [0.6, 0.25, 0.15] 
    
    # Avoid math.log2(0) if any part is 0, or if p is 1 (log2(1)=0 but 0*log0 is tricky)
    total_entropy = -sum(p * math.log2(p) for p in parts if p > 0) 
    entropy_PsiK = -parts[0] * math.log2(parts[0]) if parts[0] > 0 else 0
    entropy_Psih = -parts[2] * math.log2(parts[2]) if parts[2] > 0 else 0
    
    return {
        'total_entropy': total_entropy,
        'Ψᴷ_entropy': entropy_PsiK,
        'Ψʰ_entropy': entropy_Psih,
        'explanation': "EN: Partitioned into particles/shadows relative to Ø. PL: Podział na cząstki/cienie względem Ø."
    }

def meta_feedback_loop(fragments, initial_all_scores, iterations=5):
    """
    EN: Advanced meta-feedback loop for GTMØ. Tracks trajectory, entropy, types, and adapts heuristics dynamically. Detects emergence of new Ψ types.
    PL: Zaawansowana meta-pętla sprzężenia zwrotnego GTMØ. Śledzi trajektorie, entropię, typy, dynamicznie adaptuje heurystyki. Wykrywa emergencję nowych typów Ψ.
    """
    history = []
    thresholds_evolution = []
    types_evolution = []
    entropy_evolution = []
    new_types_detected = set()
    
    current_all_scores = list(initial_all_scores) # Use a mutable copy

    for i in range(iterations):
        iteration_scores = []
        iteration_types = []
        iteration_entropies = []
        
        # Process fragments and collect their scores for this iteration
        temp_fragment_scores = []
        processed_fragments_data = []

        for frag_idx, frag in enumerate(fragments):
            # Use current_all_scores for threshold calculation within Ψ_GTMØ
            result = Ψ_GTMØ(frag, current_all_scores) 
            
            # Safely access keys assuming Ψ_GTMØ always returns a dict for non-"Ø" or the specific "Ø" dict
            frag_score = result.get('score')
            frag_type = result.get('type')

            if frag_score is not None:
                temp_fragment_scores.append(frag_score)
            
            ent = E_GTMØ(frag)
            
            processed_fragments_data.append({
                'score': frag_score,
                'type': frag_type,
                'entropy': ent.get('total_entropy')
            })

            # --- DETEKCJA EMERGENCJI NOWYCH TYPÓW Ψ ---
            if isinstance(frag, str) and ("paradoks" in frag.lower() or "sprzeczność" in frag.lower() or "meta-" in frag.lower()):
                new_types_detected.add("Ψᴺ (novel/emergent)")
        
        # Update current_all_scores with scores from this iteration's fragments for the *next* iteration's global context
        # This is a simple way to make 'all_scores' evolve. More sophisticated logic might be needed.
        if temp_fragment_scores:
             current_all_scores.extend(temp_fragment_scores)
             # Optional: keep current_all_scores from growing indefinitely, e.g., by taking last N scores
             current_all_scores = current_all_scores[-max(len(initial_all_scores), len(current_all_scores)//2):]


        # Calculate thresholds based on the scores collected *in this iteration* or current_all_scores
        # Using current_all_scores reflects a more global, evolving context
        K_thr, H_thr = dynamic_thresholds(current_all_scores)
        thresholds_evolution.append((K_thr, H_thr))

        # Re-classify or just record types based on current fragment processing
        for data in processed_fragments_data:
            iteration_scores.append(data['score'])
            iteration_types.append(data['type'])
            iteration_entropies.append(data['entropy'])
            
        types_evolution.append(list(iteration_types)) # Ensure a copy is appended
        entropy_evolution.append(list(iteration_entropies)) # Ensure a copy is appended
        
        # Adapt thresholds based on classification outcome
        if iteration_types: # Avoid division by zero
            shadow_ratio = iteration_types.count("Ψʰ (shadow)") / len(iteration_types)
            if shadow_ratio > 0.5:
                K_thr = min(K_thr + 0.05, 1.0)
                H_thr = max(H_thr - 0.05, 0.0)
        
        history.append({
            'iteration': i + 1,
            'scores': list(iteration_scores), # Ensure a copy
            'types': list(iteration_types),   # Ensure a copy
            'thresholds': (K_thr, H_thr),     # This is the adapted threshold for *next* use or record
            'entropies': list(iteration_entropies) # Ensure a copy
        })
        
    return {
        'history': history,
        'thresholds_evolution': thresholds_evolution,
        'types_evolution': types_evolution,
        'entropy_evolution': entropy_evolution,
        'new_types_detected': list(new_types_detected)
    }

if __name__ == "__main__":
    import random
    # Initialize all_scores with a base set of scores. This list will evolve in meta_feedback_loop.
    initial_all_scores = [random.uniform(0, 1) for _ in range(99)] 
    # Add one specific score for Ø to ensure it's part of the initial distribution if desired,
    # though Ψ_GTMØ handles "Ø" specially and doesn't use its score for threshold calculation in the same way.
    # For simplicity, we'll keep initial_all_scores for general fragments.
    
    print("# AXIOMS / AKSJOMATY GTMØ")
    for i, ax in enumerate(GTMØ_axioms, 1):
        print(f"Axiom/Aksjomat {i}: {ax}")

    print("\n# DEFINITIONS / DEFINICJE")
    for i, df in enumerate(GTMØ_definitions, 1):
        print(f"Def {i}: {df}")

    print("\n# THEOREMS / TWIERDZENIA")
    for i, th in enumerate(GTMØ_theorems, 1):
        print(f"Theorem/Twierdzenie {i}: {th}")

    print("\n# OPERATIONAL THEOREMS / TWIERDZENIA OPERACYJNE")
    if GTMØ_operational_theorems: # Check if the list is not empty
        for i, th in enumerate(GTMØ_operational_theorems, 1):
            print(f"Operational Theorem/Twierdzenie Operacyjne {i}: {th}")
    else:
        print("Brak zdefiniowanych twierdzeń operacyjnych.") # Message if list is empty

    print("\n# EXAMPLES (DYNAMIC THRESHOLDS & META-FEEDBACK LOOP DEMO)")
    # Use initial_all_scores for these individual calls before the loop modifies it
    example_fragments_for_psi_demo = [f"fragment_{i}" for i in range(5)]
    if not initial_all_scores and example_fragments_for_psi_demo: # Ensure all_scores is not empty if we have fragments
        # Provide a fallback if initial_all_scores was empty for some reason
        temp_scores_for_psi_demo = [random.uniform(0,1) for _ in example_fragments_for_psi_demo]
    else:
        temp_scores_for_psi_demo = initial_all_scores

    for i, frag_name in enumerate(example_fragments_for_psi_demo):
        # Pass a non-empty list to Ψ_GTMØ for threshold calculation.
        # If temp_scores_for_psi_demo is empty, dynamic_thresholds would use a default or could error.
        # Ψ_GTMØ now handles this by passing its own score if all_scores is empty.
        wynik = Ψ_GTMØ(frag_name, temp_scores_for_psi_demo)
        print(f"Fragment {i} ('{frag_name}'): {wynik}")


    print("\n# TEST: Ψ_GTMØ on x = 'Ø' (META operator)")
    wynik_Ø = Ψ_GTMØ("Ø", initial_all_scores, operator_type=Operator.META) # all_scores isn't used for "Ø"
    print(f"Ψ_GTMØ('Ø', META): {wynik_Ø}")

    print("\n# TEST: Ψ_GTMØ on x = 'Ø' (STANDARD operator) -- expect exception")
    try:
        wynik_Ø_std = Ψ_GTMØ("Ø", initial_all_scores, operator_type=Operator.STANDARD)
        print(f"Ψ_GTMØ('Ø', STANDARD): {wynik_Ø_std}")
    except Exception as e:
        print(f"Exception (as expected): {e}")

    # --- PRZYKŁADOWE FRAGMENTY Z EMERGENCJĄ I NOWYMI TYPAMI Ψ ---
    test_fragments_emergence = [
        "W roku 1969 Neil Armstrong był pierwszym człowiekiem na Księżycu.",
        "Można powiedzieć, że każda sytuacja jest inna.",
        "To jest sprzeczność: bycie i niebycie jednocześnie.",
        "Paradoks kłamcy pokazuje granice języka.",
        "Meta-wiedza o tym, jak działają heurystyki GTMØ.",
        "Pi jest liczbą niewymierną, jej wartość to około 3.14159."
    ]
    print("\n# META-FEEDBACK LOOP / META-PĘTLA SPRZĘŻENIA ZWROTNEGO")
    # Ensure initial_all_scores is not empty if test_fragments_emergence is not empty
    # to avoid issues in dynamic_thresholds if no scores are generated internally first
    if not initial_all_scores and test_fragments_emergence:
        # Provide a fallback if initial_all_scores was empty
        loop_initial_scores = [random.uniform(0,1) for _ in test_fragments_emergence]
    else:
        loop_initial_scores = initial_all_scores
        
    meta_result = meta_feedback_loop(test_fragments_emergence, loop_initial_scores, iterations=3)
    for step in meta_result['history']:
        print(f"Iteration {step['iteration']} - Types: {step['types']}, Thresholds: {step['thresholds']}")
        # Full entropy details can be verbose, so commented out, but available in step['entropies']
        # print(f"  Entropies: {step['entropies']}") 
    print(f"\nNew Ψ types detected (Emergent): {meta_result['new_types_detected']}")

"""
# Efekty dynamicznych progów i adaptacji GTMØ:
# - Granice Ψᴷ (particles) i Ψʰ (shadows) nie są sztywne – system GTMØ automatycznie je dostraja do aktualnej epistemicznej sytuacji korpusu.
# - Zmiana progu Ψᴷ powoduje, że do tej klasy trafiają tylko najbardziej „jasne”, wyraźne fragmenty wiedzy, niezależnie od szumu i liczby przykładów.
# - Zmiana progu Ψʰ pozwala na dynamiczną detekcję fragmentów najbardziej nieokreślonych (cieni), nawet jeśli zmienia się jakość całej bazy wiedzy.
# - Jeśli całość wiedzy staje się mniej precyzyzyjna, progi się zaostrzają – GTMØ nie zaniża wymagań poznawczych!
# - Meta-feedback loop iteracyjnie może uczyć system, które progi najlepiej wyłapują realne Ψᴷ i Ψʰ w danym środowisku (meta-adaptacja, zgodna z AX7).
"""
